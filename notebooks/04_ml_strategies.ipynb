{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Trading Strategies\n",
    "\n",
    "This notebook demonstrates how to build ML-based trading strategies:\n",
    "\n",
    "1. **Feature Engineering** - Create technical features from OHLCV data\n",
    "2. **Logistic Regression** - Simple binary classification\n",
    "3. **Random Forest** - Ensemble tree-based model\n",
    "4. **Gradient Boosting** - Advanced ensemble method\n",
    "5. **Strategy Comparison** - ML vs Traditional strategies\n",
    "\n",
    "**Important**: We'll use walk-forward validation to avoid look-ahead bias!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install the library (run this cell if using Colab or if you haven't installed the package)\n!pip install --upgrade --no-cache-dir simple-backtest yfinance scikit-learn"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Any, Dict, List\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from simple_backtest import BacktestConfig, Backtest\n",
    "from simple_backtest.strategy import Strategy, MovingAverageStrategy\n",
    "from simple_backtest.visualization import plot_equity_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download data\nticker = \"AAPL\"\ndata = yf.download(ticker, start=\"2018-01-01\", end=\"2023-12-31\", progress=False)\n\n# Handle MultiIndex columns if present\nif isinstance(data.columns, pd.MultiIndex):\n    data.columns = data.columns.get_level_values(0)\n\ndata = data.dropna()\n\nprint(f\"Data shape: {data.shape}\")\nprint(f\"Date range: {data.index[0]} to {data.index[-1]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering\n",
    "\n",
    "Create technical features that ML models can learn from:\n",
    "- Returns and momentum\n",
    "- Moving averages\n",
    "- Volatility\n",
    "- RSI\n",
    "- Volume indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create technical features for ML models.\"\"\"\n",
    "    features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Price features\n",
    "    features['returns'] = df['Close'].pct_change()\n",
    "    features['returns_5'] = df['Close'].pct_change(5)\n",
    "    features['returns_10'] = df['Close'].pct_change(10)\n",
    "    features['returns_20'] = df['Close'].pct_change(20)\n",
    "    \n",
    "    # Moving averages\n",
    "    features['sma_5'] = df['Close'].rolling(5).mean() / df['Close'] - 1\n",
    "    features['sma_10'] = df['Close'].rolling(10).mean() / df['Close'] - 1\n",
    "    features['sma_20'] = df['Close'].rolling(20).mean() / df['Close'] - 1\n",
    "    features['sma_50'] = df['Close'].rolling(50).mean() / df['Close'] - 1\n",
    "    \n",
    "    # Volatility\n",
    "    features['volatility_5'] = df['Close'].pct_change().rolling(5).std()\n",
    "    features['volatility_20'] = df['Close'].pct_change().rolling(20).std()\n",
    "    \n",
    "    # RSI\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    features['rsi'] = 100 - (100 / (1 + rs))\n",
    "    features['rsi'] = (features['rsi'] - 50) / 50  # Normalize to [-1, 1]\n",
    "    \n",
    "    # Volume features\n",
    "    features['volume_ratio'] = df['Volume'] / df['Volume'].rolling(20).mean()\n",
    "    features['volume_change'] = df['Volume'].pct_change()\n",
    "    \n",
    "    # Price position in range\n",
    "    features['high_low_ratio'] = (df['Close'] - df['Low']) / (df['High'] - df['Low'])\n",
    "    \n",
    "    # Momentum\n",
    "    features['momentum_5'] = df['Close'] / df['Close'].shift(5) - 1\n",
    "    features['momentum_10'] = df['Close'] / df['Close'].shift(10) - 1\n",
    "    \n",
    "    # Drop NaN values\n",
    "    features = features.dropna()\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Create features\n",
    "features_df = create_features(data)\n",
    "\n",
    "print(f\"\\nFeatures shape: {features_df.shape}\")\n",
    "print(f\"\\nFeatures:\")\n",
    "print(features_df.columns.tolist())\n",
    "print(f\"\\nSample:\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target: 1 if next day's return is positive, 0 otherwise\n",
    "features_df['target'] = (data.loc[features_df.index, 'Close'].pct_change().shift(-1) > 0).astype(int)\n",
    "features_df = features_df.dropna()\n",
    "\n",
    "print(f\"Target distribution:\")\n",
    "print(features_df['target'].value_counts())\n",
    "print(f\"\\nPositive days: {features_df['target'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ML Strategy Base Class\n",
    "\n",
    "Create a base class for ML strategies that handles:\n",
    "- Training window management\n",
    "- Feature calculation on the fly\n",
    "- Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLStrategy(Strategy):\n",
    "    \"\"\"Base class for ML-based trading strategies.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, training_window: int = 500, retrain_interval: int = 50,\n",
    "                 shares: float = 10, name: str = None):\n",
    "        super().__init__(name=name or f\"ML_{model.__class__.__name__}\")\n",
    "        self.model = model\n",
    "        self.scaler = StandardScaler()\n",
    "        self.training_window = training_window\n",
    "        self.retrain_interval = retrain_interval\n",
    "        self.shares = shares\n",
    "        self.days_since_training = 0\n",
    "        self.is_trained = False\n",
    "    \n",
    "    def create_features_from_data(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create features from OHLCV data.\"\"\"\n",
    "        return create_features(data)\n",
    "    \n",
    "    def train_model(self, data: pd.DataFrame):\n",
    "        \"\"\"Train the model on historical data.\"\"\"\n",
    "        # Create features\n",
    "        features = self.create_features_from_data(data)\n",
    "        \n",
    "        if len(features) < 100:  # Need minimum data\n",
    "            return False\n",
    "        \n",
    "        # Create target (next day return > 0)\n",
    "        target = (data.loc[features.index, 'Close'].pct_change().shift(-1) > 0).astype(int)\n",
    "        \n",
    "        # Align features and target\n",
    "        valid_idx = features.index.intersection(target.dropna().index)\n",
    "        features = features.loc[valid_idx]\n",
    "        target = target.loc[valid_idx]\n",
    "        \n",
    "        if len(features) < 50:\n",
    "            return False\n",
    "        \n",
    "        # Drop target column if exists\n",
    "        if 'target' in features.columns:\n",
    "            features = features.drop('target', axis=1)\n",
    "        \n",
    "        # Scale features\n",
    "        X = self.scaler.fit_transform(features)\n",
    "        y = target.values\n",
    "        \n",
    "        # Train model\n",
    "        self.model.fit(X, y)\n",
    "        self.feature_names = features.columns.tolist()\n",
    "        self.is_trained = True\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def predict(self, data: pd.DataFrame, trade_history: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        # Check if we need to train or retrain\n",
    "        if not self.is_trained or self.days_since_training >= self.retrain_interval:\n",
    "            # Use full lookback for training\n",
    "            training_data = data.tail(min(self.training_window, len(data)))\n",
    "            self.train_model(training_data)\n",
    "            self.days_since_training = 0\n",
    "        \n",
    "        self.days_since_training += 1\n",
    "        \n",
    "        if not self.is_trained:\n",
    "            return self.hold()\n",
    "        \n",
    "        # Create features for current data\n",
    "        try:\n",
    "            features = self.create_features_from_data(data)\n",
    "            \n",
    "            if len(features) == 0:\n",
    "                return self.hold()\n",
    "            \n",
    "            # Get latest features\n",
    "            latest_features = features.iloc[-1:]\n",
    "            \n",
    "            # Drop target if exists\n",
    "            if 'target' in latest_features.columns:\n",
    "                latest_features = latest_features.drop('target', axis=1)\n",
    "            \n",
    "            # Ensure same features as training\n",
    "            latest_features = latest_features[self.feature_names]\n",
    "            \n",
    "            # Scale features\n",
    "            X = self.scaler.transform(latest_features)\n",
    "            \n",
    "            # Get prediction and probability\n",
    "            prediction = self.model.predict(X)[0]\n",
    "            \n",
    "            # Get prediction probability if available\n",
    "            if hasattr(self.model, 'predict_proba'):\n",
    "                prob = self.model.predict_proba(X)[0][1]  # Probability of class 1\n",
    "                confidence_threshold = 0.55  # Only trade if confident\n",
    "                \n",
    "                # Buy signal: predict up with confidence\n",
    "                if prediction == 1 and prob > confidence_threshold and not self.has_position():\n",
    "                    return self.buy(self.shares)\n",
    "                \n",
    "                # Sell signal: predict down with confidence\n",
    "                if prediction == 0 and prob < (1 - confidence_threshold) and self.has_position():\n",
    "                    return self.sell(self.shares)\n",
    "            else:\n",
    "                # For models without probability (like some linear models)\n",
    "                if prediction == 1 and not self.has_position():\n",
    "                    return self.buy(self.shares)\n",
    "                elif prediction == 0 and self.has_position():\n",
    "                    return self.sell(self.shares)\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If any error in feature calculation or prediction, hold\n",
    "            pass\n",
    "        \n",
    "        return self.hold()\n",
    "    \n",
    "    def reset_state(self):\n",
    "        super().reset_state()\n",
    "        self.days_since_training = 0\n",
    "        self.is_trained = False\n",
    "\n",
    "print(\"âœ“ MLStrategy base class created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression Strategy\n",
    "\n",
    "Simple linear model - fast and interpretable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Logistic Regression strategy\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_strategy = MLStrategy(\n",
    "    model=lr_model,\n",
    "    training_window=500,\n",
    "    retrain_interval=50,\n",
    "    shares=10,\n",
    "    name=\"LogisticRegression\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ Logistic Regression strategy created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Random Forest Strategy\n",
    "\n",
    "Ensemble of decision trees - handles non-linear relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Random Forest strategy\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_strategy = MLStrategy(\n",
    "    model=rf_model,\n",
    "    training_window=500,\n",
    "    retrain_interval=50,\n",
    "    shares=10,\n",
    "    name=\"RandomForest\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ Random Forest strategy created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gradient Boosting Strategy\n",
    "\n",
    "Advanced ensemble method - builds trees sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradient Boosting strategy\n",
    "gb_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "gb_strategy = MLStrategy(\n",
    "    model=gb_model,\n",
    "    training_window=500,\n",
    "    retrain_interval=50,\n",
    "    shares=10,\n",
    "    name=\"GradientBoosting\"\n",
    ")\n",
    "\n",
    "print(\"âœ“ Gradient Boosting strategy created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare ML Strategies with Traditional Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure backtest\n",
    "config = BacktestConfig(\n",
    "    initial_capital=10000.0,\n",
    "    lookback_period=100,  # Need longer lookback for ML features\n",
    "    commission_type=\"percentage\",\n",
    "    commission_value=0.001,\n",
    "    risk_free_rate=0.02\n",
    ")\n",
    "\n",
    "# Include traditional strategy for comparison\n",
    "ma_strategy = MovingAverageStrategy(\n",
    "    short_window=10,\n",
    "    long_window=30,\n",
    "    shares=10,\n",
    "    name=\"MA_Traditional\"\n",
    ")\n",
    "\n",
    "# All strategies\n",
    "strategies = [\n",
    "    lr_strategy,\n",
    "    rf_strategy,\n",
    "    gb_strategy,\n",
    "    ma_strategy,\n",
    "]\n",
    "\n",
    "print(\"Testing strategies:\")\n",
    "for s in strategies:\n",
    "    print(f\"  - {s.get_name()}\")\n",
    "\n",
    "print(\"\\nâ³ Running backtest... (ML strategies take longer due to training)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backtest (disable parallel execution for ML strategies to avoid issues)\n",
    "config.parallel_execution = False\n",
    "\n",
    "backtest = Backtest(data=data, config=config)\n",
    "results = backtest.run(strategies)\n",
    "\n",
    "print(\"\\nâœ“ Backtest completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results\n",
    "comparison_df = results.compare()\n",
    "\n",
    "print(\"\\nML vs Traditional Strategy Comparison:\")\n",
    "print(\"=\" * 120)\n",
    "display_cols = ['total_return', 'cagr', 'sharpe_ratio', 'sortino_ratio', 'max_drawdown', \n",
    "                'total_trades', 'win_rate', 'profit_factor']\n",
    "print(comparison_df[display_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Best strategies by different metrics\nprint(\"\\n\" + \"=\"*70)\nprint(\"BEST STRATEGIES\")\nprint(\"=\"*70)\n\nfor metric in ['sharpe_ratio', 'total_return', 'win_rate']:\n    best = results.best_strategy(metric)  # Returns StrategyResult object\n    value = best.metrics[metric]\n    \n    if 'return' in metric or 'rate' in metric or 'drawdown' in metric:\n        print(f\"\\nBest by {metric}: {best.name} = {value*100:.2f}%\")\n    else:\n        print(f\"\\nBest by {metric}: {best.name} = {value:.2f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig = results.plot_comparison()\n",
    "fig.update_layout(title=\"ML vs Traditional Strategies - Equity Curves\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Analysis: Best ML Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Find best ML strategy\nml_strategies = ['LogisticRegression', 'RandomForest', 'GradientBoosting']\nml_sharpe = {name: results[name]['metrics']['sharpe_ratio'] for name in ml_strategies}\nbest_ml = max(ml_sharpe, key=ml_sharpe.get)\n\nprint(f\"Best ML Strategy: {best_ml}\\n\")\n\nmetrics = results[best_ml]['metrics']\n\nprint(\"=\" * 80)\nprint(f\"{best_ml.upper()} - DETAILED METRICS\")\nprint(\"=\" * 80)\n\nprint(f\"\\nðŸ“Š Returns:\")\nprint(f\"  Total Return:        {metrics['total_return']*100:>10.2f}%\")\nprint(f\"  CAGR:                {metrics['cagr']*100:>10.2f}%\")\n\nprint(f\"\\nâš¡ Risk-Adjusted Returns:\")\nprint(f\"  Sharpe Ratio:        {metrics['sharpe_ratio']:>10.2f}\")\nprint(f\"  Sortino Ratio:       {metrics['sortino_ratio']:>10.2f}\")\nprint(f\"  Calmar Ratio:        {metrics['calmar_ratio']:>10.2f}\")\n\nprint(f\"\\nâš ï¸  Risk Metrics:\")\nprint(f\"  Max Drawdown:        {metrics['max_drawdown']*100:>10.2f}%\")\nprint(f\"  Volatility:          {metrics['volatility']*100:>10.2f}%\")\n\nprint(f\"\\nðŸ“ˆ Trading Performance:\")\nprint(f\"  Total Trades:        {metrics['total_trades']:>10}\")\nprint(f\"  Win Rate:            {metrics['win_rate']*100:>10.2f}%\")\nprint(f\"  Profit Factor:       {metrics['profit_factor']:>10.2f}\")\nprint(f\"  Avg Win:             ${metrics['avg_win']:>10.2f}\")\nprint(f\"  Avg Loss:            ${metrics['avg_loss']:>10.2f}\")\n\nprint(f\"\\nðŸŽ¯ vs Benchmark:\")\nprint(f\"  Alpha:               {metrics['alpha']*100:>10.2f}%\")\nprint(f\"  Beta:                {metrics['beta']:>10.2f}\")\nprint(f\"  Information Ratio:   {metrics['information_ratio']:>10.2f}\")\n\nprint(\"\\n\" + \"=\"*80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance (for Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature importance for Random Forest if it's trained\n",
    "if rf_strategy.is_trained and hasattr(rf_strategy.model, 'feature_importances_'):\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': rf_strategy.feature_names,\n",
    "        'importance': rf_strategy.model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nRandom Forest - Top 10 Most Important Features:\")\n",
    "    print(\"=\" * 50)\n",
    "    for idx, row in importance_df.head(10).iterrows():\n",
    "        print(f\"  {row['feature']:.<30} {row['importance']:.4f}\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we built ML-based trading strategies:\n",
    "\n",
    "1. âœ… **Feature Engineering**: Created 15+ technical features from OHLCV data\n",
    "2. âœ… **Logistic Regression**: Simple linear classifier\n",
    "3. âœ… **Random Forest**: Ensemble tree-based model\n",
    "4. âœ… **Gradient Boosting**: Advanced sequential ensemble\n",
    "5. âœ… **Strategy Comparison**: ML vs traditional strategies\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "**Advantages of ML Strategies:**\n",
    "- Can capture complex non-linear relationships\n",
    "- Automatically learn from multiple features\n",
    "- Adapt to changing market conditions through retraining\n",
    "- Can incorporate many indicators simultaneously\n",
    "\n",
    "**Challenges:**\n",
    "- Risk of overfitting (learning noise instead of signal)\n",
    "- Require careful feature engineering\n",
    "- Need sufficient training data\n",
    "- Computationally expensive (especially retraining)\n",
    "- Harder to interpret than rule-based strategies\n",
    "\n",
    "### Best Practices for ML Trading:\n",
    "\n",
    "1. **Walk-Forward Validation**: Always use rolling training windows (no look-ahead bias)\n",
    "2. **Regular Retraining**: Markets change - retrain periodically\n",
    "3. **Feature Selection**: More features â‰  better performance\n",
    "4. **Ensemble Methods**: Combine multiple models for robustness\n",
    "5. **Probability Thresholds**: Only trade when model is confident\n",
    "6. **Risk Management**: ML signals need stop-losses too\n",
    "7. **Transaction Costs**: ML strategies often trade more - watch commissions\n",
    "\n",
    "### Performance Tips:\n",
    "\n",
    "- **Feature Scaling**: Always normalize/standardize features\n",
    "- **Class Balance**: Handle imbalanced buy/sell signals\n",
    "- **Cross-Validation**: Use time-series CV, not random CV\n",
    "- **Hyperparameter Tuning**: Optimize model parameters\n",
    "- **Avoid Overfitting**: Use regularization, limit tree depth\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Add more advanced features (technical patterns, sentiment)\n",
    "- Try deep learning models (LSTM, Transformers)\n",
    "- Implement position sizing based on prediction confidence\n",
    "- Add regime detection to switch between strategies\n",
    "- Create ensemble strategies combining multiple ML models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}